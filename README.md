ğŸ§  SYNAPSE: Gesture + Voice Powered Multimodal Controller

**Synapse** is a smart, hands-free desktop controller that combines real-time **hand gesture recognition** and a responsive **voice assistant**, empowering users to navigate, interact, and perform system actions effortlessly. Ideal for accessibility, multitasking, and touchless control.

> Built using OpenCV, MediaPipe, pyautogui, and Gemini AI (optional).

---

## ğŸš€ Features

- ğŸ¯ **Hand Gesture Control**  
  - Move mouse with your index finger  
  - Left click, right click, double-click  
  - Scroll up/down using open palm  
  - Take screenshots with specific gestures  
  - Zoom in/out using pinch gestures  
  - Toggle gesture UI in real-time

- ğŸ™ï¸ **Voice Assistant (Offline + AI Mode)**  
  - Open apps/websites like Google, YouTube, Leetcode, etc.  
  - Speak commands like "open documents", "what time is it", etc.  
  - Ask general questions via Gemini AI (if API key is configured)

- ğŸ§  **AI-Enhanced Mode (Optional)**  
  - Use Google's Gemini API to get AI-generated responses  
  - Responses are saved for future reference

- ğŸ› ï¸ **Configurable & Adaptive**
  - UI overlay for gesture feedback  
  - Smoothing for cursor movement  
  - Voice input mic selector and tester
